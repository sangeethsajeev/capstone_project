{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTM-Training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9qVte_1OrH2"
      },
      "source": [
        "\n",
        "import sagemaker\n",
        "from sagemaker.tensorflow import TensorFlow\n",
        "from sagemaker import get_execution_role\n",
        "from pandas import read_csv\n",
        "from urllib.parse import urlparse\n",
        "import os\n",
        "import boto3\n",
        "    \n",
        "###Turn off warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "if type(tensorflow.contrib) != type(tensorflow): tensorflow.contrib._warning = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wrbc309dOvZ2"
      },
      "source": [
        "s3Bucket = \"XYZ-S3Bucket-XYZ\"\n",
        "dataset = \"XYZ-IotAnalyticsDataset-XYZ\"\n",
        "\n",
        "iotanalytics_client = boto3.client('iotanalytics')\n",
        "dataset_url = iotanalytics_client.get_dataset_content(datasetName = dataset)['entries'][0]['dataURI']\n",
        "\n",
        "dataset = read_csv(dataset_url, header=0, index_col='date')\n",
        "if dataset.empty:\n",
        "    raise Exception('No data found')\n",
        "dataset.sort_index(inplace=True)\n",
        "#dataset = dataset[['pollution', 'dew', 'temp', 'press', 'wnd_dir', 'wnd_spd', 'snow', 'rain']]\n",
        "dataset.drop_duplicates(inplace=True)\n",
        "dataset.to_csv('pollution.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCNxke61O8FU"
      },
      "source": [
        "###Upload this queried data to s3\n",
        "sagemaker_session = sagemaker.Session()\n",
        "uploaded_data_path = sagemaker_session.upload_data(path='pollution.csv', bucket=s3Bucket, key_prefix='data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6LDqfdGPOov"
      },
      "source": [
        "train_instance_type = \"ml.m5.xlarge\"\n",
        "    \n",
        "tf_estimator = TensorFlow(entry_point='trainLSTM.py', role=get_execution_role(),\n",
        "                          train_instance_count=1, train_instance_type=train_instance_type,\n",
        "                          framework_version='1.12', py_version='py3', script_mode=True,\n",
        "                          output_path = 's3://' + s3Bucket, base_job_name = \"pollution-forecasting-lstm\",\n",
        "                          hyperparameters={'batch_size': 72,\n",
        "                                           'epochs': 50,\n",
        "                                           'n_train_hours': n_train_hours,\n",
        "                                           'n_validation_hours': n_validation_hours})\n",
        "\n",
        "tf_estimator.fit(uploaded_data_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}